# Lustre IO500
This document contains the Lustre performance measurement for IO500.

## Reference
剑桥大学Lustre IO500跑分：https://www.eofs.eu/_media/events/lad19/03_matt_raso-barnett-io500-cambridge.pdf

Linux 内核链表介绍：https://www.bilibili.com/read/cv14688084/

内核使用container_of()函数实现，这个函数能够通过结构体内部成员的地址找到结构体本身的地址，这样就可以通过链表的地址得到数据结构体的地址，然后就可以获得其他数据了。

## Features for Performance Boosting

### Lustre Multi-Rail
之前测试过920机器，同一张100G网卡的两个网口，带宽看起来是公用的，最多能撑100G带宽。一个插槽感觉只能使用一个100G网口，估计需要两张网卡放在不同CPU socket的插槽。这样才能利用不同CPU socket的内存和PCIE链路带宽，我看SPDK官方测试是这样100G网卡的

#### MultiRail Reference

https://wiki.whamcloud.com/display/LNet/Multi-Rail+Overview

[MultiRail Author to introduce Multi Rail in LAD](https://wiki.whamcloud.com/plugins/servlet/mobile?contentId=133798192#content/view/133798192)

[MultiRail High Level Design](https://wiki.lustre.org/images/b/bb/Multi-Rail_High-Level_Design_20150119.pdf)

### Lustre DNE2
https://wiki.opensfs.org/images/f/ff/DNE_StripedDirectories_HighLevelDesign.pdf
http://lustrefs.cn/wp-content/uploads/2020/11/CLUG2020_%E8%B5%96%E6%96%AF%E9%81%A5_Lustre%E5%A4%9A%E5%85%83%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95.pdf

MPI教程：https://mpitutorial.com/tutorials/，中文

/home/lustre_results/2022.09.15-13.46.14

## Lustre Bugs
### PTLRPC Crash
```
[29155.237003] Lustre: 2817844:0:(service.c:1436:ptlrpc_at_send_early_reply()) Skipped 262085 previous similar messages
[29257.712448] LustreError: 2818852:0:(service.c:929:ptlrpc_server_drop_request()) ASSERTION( list_empty(&req->rq_srv.sr_timed_list) ) failed: 
[29257.725017] LustreError: 2818852:0:(service.c:929:ptlrpc_server_drop_request()) LBUG
[29257.732738] Pid: 2818852, comm: ldlm_cn00_111 4.18.0-372.9.1.el8.aarch64 #1 SMP Thu Sep 1 12:58:30 CST 2022
[29257.742444] Call Trace:
[29257.744888] [<0>] libcfs_call_trace+0xac/0x120 [libcfs]
[29257.750129] [<0>] lbug_with_loc+0x50/0x90 [libcfs]
[29257.754927] [<0>] ptlrpc_server_drop_request+0x618/0x8a8 [ptlrpc]
[29257.761176] [<0>] ptlrpc_server_handle_req_in+0x260/0xf48 [ptlrpc]
[29257.767466] [<0>] ptlrpc_main+0xcdc/0x15a0 [ptlrpc]
[29257.772452] [<0>] kthread+0x124/0x130
[29257.776107] [<0>] ret_from_fork+0x10/0x18
[29257.780113] Kernel panic - not syncing: LBUG
[29257.784363] CPU: 7 PID: 2818852 Comm: ldlm_cn00_111 Kdump: loaded Tainted: P           OE    --------- -  - 4.18.0-372.9.1.el8.aarch64 #1
[29257.796652] Hardware name: Huawei TaiShan 200 (Model 2280)/BC82AMDDA, BIOS 1.35 04/30/2020
[29257.804877] Call trace:
[29257.807313]  dump_backtrace+0x0/0x158
[29257.810961]  show_stack+0x24/0x30
[29257.814262]  dump_stack+0x5c/0x74
[29257.817563]  panic+0x13c/0x308
[29257.820606]  param_set_delay_minmax.isra.0+0x0/0xd8 [libcfs]
[29257.826262]  ptlrpc_server_drop_request+0x618/0x8a8 [ptlrpc]
[29257.832023]  ptlrpc_server_handle_req_in+0x260/0xf48 [ptlrpc]
[29257.837849]  ptlrpc_main+0xcdc/0x15a0 [ptlrpc]
[29257.842379]  kthread+0x124/0x130
[29257.845594]  ret_from_fork+0x10/0x18
[29257.849207] SMP: stopping secondary CPUs
[29257.855038] Starting crashdump kernel...
[29257.858946] Bye!
```

ptl_rpc_main
ptlrpc_server_handle_req_in
ptlrpc_server_finish_request

```angular2html
/**
 * Handle freshly incoming reqs, add to timed early reply list,
 * pass on to regular request queue.
 * All incoming requests pass through here before getting into
 * ptlrpc_server_handle_req later on.
 */

static int ptlrpc_server_handle_req_in(struct ptlrpc_service_part *svcpt,
				       struct ptlrpc_thread *thread)
{
	struct ptlrpc_service *svc = svcpt->scp_service;
	struct ptlrpc_request *req;
	__u32 deadline;
	__u32 opc;
	int rc;

	ENTRY;

// 拿到锁之后，才能进行coming request的预处理。因此下面等待spinlock
	spin_lock(&svcpt->scp_lock);
// 参看下方的request_in_callback, scp_req_incoming在那里被赋值
	if (list_empty(&svcpt->scp_req_incoming)) {
		spin_unlock(&svcpt->scp_lock);
		RETURN(0);
	}

//从scp_req_incoming取出列表第一项，
	req = list_first_entry(&svcpt->scp_req_incoming,
			       struct ptlrpc_request, rq_list);
// req的rq_list从链表取出删除entry
	list_del_init(&req->rq_list);
	svcpt->scp_nreqs_incoming--;
	/*
	 * Consider this still a "queued" request as far as stats are
	 * concerned
	 */
	spin_unlock(&svcpt->scp_lock);
-----------------------------------离开临界区
	/* go through security check/transform */
	rc = sptlrpc_svc_unwrap_request(req);
	switch (rc) {
	case SECSVC_OK:
		break;
	case SECSVC_COMPLETE:
		target_send_reply(req, 0, OBD_FAIL_MDS_ALL_REPLY_NET);
		goto err_req;
	case SECSVC_DROP:
		goto err_req;
	default:
		LBUG();
	}

.......................

	ptlrpc_at_add_timed(req);

	if (opc != OST_CONNECT && opc != MDS_CONNECT &&
	    opc != MGS_CONNECT && req->rq_export != NULL) {
		if (exp_connect_flags2(req->rq_export) & OBD_CONNECT2_REP_MBITS)
			req->rq_rep_mbits = lustre_msg_get_mbits(req->rq_reqmsg);
	}

	/* Move it over to the request processing queue */
	rc = ptlrpc_server_request_add(svcpt, req);
	if (rc)
		GOTO(err_req, rc);

	wake_up(&svcpt->scp_waitq);
	RETURN(1);

err_req:
	ptlrpc_server_finish_request(svcpt, req);

	RETURN(1);
```

ptlrpc_server_request_add
ptlrpc_at_add_timed /* Add rpc to early reply check list */

```angular2html
struct ptlrpc_srv_req {
	/** initial thread servicing this request */
	struct ptlrpc_thread		*sr_svc_thread;
	/**
	 * Server side list of incoming unserved requests sorted by arrival
	 * time.  Traversed from time to time to notice about to expire
	 * requests and sent back "early replies" to clients to let them
	 * know server is alive and well, just very busy to service their
	 * requests in time
	 */
	struct list_head		 sr_timed_list;

```
#define rq_timed_list		rq_srv.sr_timed_list

```angular2html
struct ptlrpc_request {
..............
	/** non-shared members for client & server request*/
	union {
		struct ptlrpc_cli_req	 rq_cli;
		struct ptlrpc_srv_req	 rq_srv;
	};
..............
```

static int ptlrpc_at_add_timed(struct ptlrpc_request *req)
```angular2html
/* Add rpc to early reply check list */
static int ptlrpc_at_add_timed(struct ptlrpc_request *req)
{
	struct ptlrpc_service_part *svcpt = req->rq_rqbd->rqbd_svcpt;
	struct ptlrpc_at_array *array = &svcpt->scp_at_array;
	struct ptlrpc_request *rq = NULL;
	__u32 index;

	if (AT_OFF)
		return(0);

	if (req->rq_no_reply)
		return 0;

	if ((lustre_msghdr_get_flags(req->rq_reqmsg) & MSGHDR_AT_SUPPORT) == 0)
		return(-ENOSYS);

	spin_lock(&svcpt->scp_at_lock);
// 此时req刚进来，所以还没有被挂在rq_timed_list中。为初始化值。
	LASSERT(list_empty(&req->rq_timed_list));

// static inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)；//无符号除法操作：除数是无符号64bit，被除数是无符号32，remainder为余数
	div_u64_rem(req->rq_deadline, array->paa_size, &index);

	if (array->paa_reqs_count[index] > 0) {
		/*
		 * latest rpcs will have the latest deadlines in the list,
		 * so search backward.
		 */                         pos    head 
		list_for_each_entry_reverse(rq, &array->paa_reqs_array[index],
					    rq_timed_list) {
// 如果req的deadline在rq大，那么将req放到rq后面。
			if (req->rq_deadline >= rq->rq_deadline) {
				list_add(&req->rq_timed_list,
					 &rq->rq_timed_list);
				break;
			}
		}
	}
    // 如果req->rq_timed_list仍是空，则说明前面也没执行，因此array->pass_reqs_array没东西，所以讲req放到array里面。
    // 如果rq_timed_list不是空，则说明此时
    /* Add the request at the head of the list */
	if (list_empty(&req->rq_timed_list))
		list_add(&req->rq_timed_list, &array->paa_reqs_array[index]);

// rq_at_linked:    /**< link into service's srv_at_array */
	spin_lock(&req->rq_lock);
	req->rq_at_linked = 1;
	spin_unlock(&req->rq_lock);
	req->rq_at_index = index;
	array->paa_reqs_count[index]++;
	array->paa_count++;
	if (array->paa_count == 1 || array->paa_deadline > req->rq_deadline) {
		array->paa_deadline = req->rq_deadline;
		ptlrpc_at_set_timer(svcpt);
	}
	spin_unlock(&svcpt->scp_at_lock);

	return 0;
}

```


20220919 Lustre性能讨论
https://linaro-org.zoom.us/recording/detail?meeting_id=vUu%2FgPm3SOG9fV%2BcfA2AhA%3D%3D

request_in_callback
struct ptlrpc_request		  *req;
	ptlrpc_srv_req_init(req);
```angular2html
/** initialise server side ptlrpc request */
static inline void ptlrpc_srv_req_init(struct ptlrpc_request *req)
{
	struct ptlrpc_srv_req *sr = &req->rq_srv;

	ptlrpc_req_comm_init(req);
	req->rq_srv_req = 1;
	INIT_LIST_HEAD(&sr->sr_exp_list);
	INIT_LIST_HEAD(&sr->sr_timed_list);   /////
	INIT_LIST_HEAD(&sr->sr_hist_list);
}
```

ptlrpc_main函数
/**
 * Main thread body for service threads.
 * Waits in a loop waiting for new requests to process to appear.
 * Every time an incoming requests is added to its queue, a waitq
 * is woken up and one of the threads will handle it.
 */
    static int ptlrpc_main(void *arg)
    /* XXX maintain a list of all managed devices: insert here */
    while (!ptlrpc_thread_stopping(thread)) {

当请求进来时，
/*
 * Server's incoming request callback
 */
 request_in_callback
1. ptlrpc_srv_req_init(req);
2. spin_lock(&svcpt->scp_lock)临界区
3. ev->unlink check 不懂啥意思
4. 将req的list加入到scp_req_incoming中。list_add_tail(&req->rq_list, &svcpt->scp_req_incoming);
    svcpt->scp_nreqs_incoming++;
5. 	/* NB everything can disappear under us once the request
	 * has been queued and we unlock, so do the wake now... */
	wake_up(&svcpt->scp_waitq);

	spin_unlock(&svcpt->scp_lock);

```angular2html
/**
 * drop a reference count of the request. if it reaches 0, we either
 * put it into history list, or free it immediately.
 */
void ptlrpc_server_drop_request(struct ptlrpc_request *req)
{
	struct ptlrpc_request_buffer_desc *rqbd = req->rq_rqbd;
	struct ptlrpc_service_part	  *svcpt = rqbd->rqbd_svcpt;
	struct ptlrpc_service		  *svc = svcpt->scp_service;
	int				   refcount;

// rq_refcount减1后是0，则返回1.否则返回0. 这里refcount为1的话，返回1，无法进入return。
	if (!atomic_dec_and_test(&req->rq_refcount))
		return;

	if (req->rq_session.lc_state == LCS_ENTERED) {
		lu_context_exit(&req->rq_session);
		lu_context_fini(&req->rq_session);
	}
// 这里rq_at_linked /**< link into service's srv_at_array */
// 即在svc的array里面。ptlrpc_at_add_timed中会有个临界区中把此处置1.
	if (req->rq_at_linked) {
		spin_lock(&svcpt->scp_at_lock);
		/*
		 * recheck with lock, in case it's unlinked by
		 * ptlrpc_at_check_timed()
		 */
		if (likely(req->rq_at_linked))
// 此时会调用如下函数，清除掉req->rq_timed_list
			ptlrpc_at_remove_timed(req);
		spin_unlock(&svcpt->scp_at_lock);
	}
// 会不会req->rq_at_linked为0，但是rq_timed_list此处未被从list删除，导致了LBUG。 需要参考上文对ptlrpc_at_add_timed的分析
	LASSERT(list_empty(&req->rq_timed_list));

```

## 测试环境IO500 参数配置：
```angular2html
#!/bin/bash -x
#SBATCH --nodes=10 --ntasks-per-node=6 -p compute -A ku0598

LUSTRE_MDS=server[1-5,10]
LUSTRE_OSS=server[1-5,10]
LUSTRE_CLIENT=client[1-7]

ROOT=`pwd`
#module purge
#module load mpi/gcc/openmpi/4.0.4
PDSH="pdsh"

# Lustre MDS/OSS Setting
$PDSH -w ${LUSTRE_MDS} "echo 128 > /sys/module/mdt/parameters/max_mod_rpcs_per_client"
$PDSH -w ${LUSTRE_OSS},${LUSTRE_MDS} "sysctl -w vm.min_free_kbytes=524288"
$PDSH -w ${LUSTRE_OSS} lctl set_param \
osd-ldiskfs.*.read_cache_enable=0 \
osd-ldiskfs.*.writethrough_cache_enable=0 \
obdfilter.*.brw_size=16 \
obdfilter.*.precreate_batch=1024 \
osp.*.max_rpcs_in_flight=128


$PDSH -w ${LUSTRE_CLIENT},${LUSTRE_MDS},${LUSTRE_OSS} lctl get_param version
sleep 2

# Lustre Client Setting
$PDSH -w ${LUSTRE_CLIENT} lctl set_param \
osc.*.max_pages_per_rpc=1048576 \
osc.*.max_rpcs_in_flight=256 \
osc.*.max_dirty_mb=2000 \
osc.*.checksums=0 \
osc.*.short_io_bytes=65536 \
llite.*.max_read_ahead_mb=2048 \
llite.*.max_read_ahead_per_file_mb=16 \
llite.*.max_cached_mb=8192 \
ldlm.namespaces.*.lru_size=0 \
ldlm.namespaces.*.lru_max_age=5000 \
mdc.*.max_rpcs_in_flight=128 \
mdc.*.max_mod_rpcs_in_flight=8
sleep 2

# Cleanup & TRIM to all OSTs
$PDSH -w ${LUSTRE_CLIENT} lctl set_param ldlm.namespaces.*.lru_size=clear
#$PDSH -w ${LUSTRE_OSS} fstrim -av
#$PDSH -w ${LUSTRE_MDS},${LUSTRE_OSS} "echo 3 > /proc/sys/vm/drop_caches"
#$PDSH -w ${LUSTRE_CLIENT} "cpupower frequency-set -g performance"

# INSTRUCTIONS:
#
# The only parts of the script that may need to be modified are:
#  - setup() to configure the binary locations and MPI parameters
# Please visit https://vi4io.org/io500-info-creator/ to help generate the
# "system-information.txt" file, by pasting the output of the info-creator.
# This file contains details of your system hardware for your submission.

# This script takes its parameters from the same .ini file as io500 binary.
io500_ini="$1"          # You can set the ini file here
io500_mpirun="mpiexec"
#io500_mpiargs="--mca btl openib,self,vader --mca btl_openib_ipaddr_include '192.168.0.0/24'  --mca btl_openib_allow_ib 1 -hostfile hosts8 --map-by node  -np "
#io500_mpiargs="--mca io romio321 --mca btl openib,self,vader --mca btl_openib_ipaddr_include '192.168.0.0/24'  --mca btl_openib_allow_ib 1 -hostfile hosts8 --map-by node  -np "
#io500_mpiargs="--mca btl openib,self,vader --mca btl_openib_ipaddr_include '192.168.0.0/24'  --mca btl_openib_allow_ib 1 -hostfile hosts8 --map-by node  -np "
#io500_mpiargs="-hostfile hosts8 --map-by node  --mca btl openib,self,vader --mca btl_openib_allow_ib 1 --mca btl_openib_if_include mlx5_2,mlx5_1,mlx5_0  -np "
io500_mpiargs=" --mca btl tcp,self,vader  -hostfile hosts8 --map-by node  -np "

#io500_mpiargs="-hostfile hosts8 --map-by node  --mca btl openib,self,vader --mca btl_openib_allow_ib 1 --mca btl_openib_if_include mlx5_2,mlx5_1,mlx5_0  -np "
#io500_mpiargs="--mca pml ucx -hostfile hosts8 --map-by node  -np "
np=$2

function setup(){
  local workdir="$1"
  local resultdir="$2"
  mkdir -p $workdir $resultdir

  # Example commands to create output directories for Lustre.  Creating
  # top-level directories is allowed, but not the whole directory tree.
  lfs setstripe -c 1 $workdir
  mkdir $workdir/ior-easy $workdir/ior-hard
  mkdir $workdir/mdtest-easy $workdir/mdtest-hard
  local osts=$(lfs df $workdir | grep -c OST)
  # Try overstriping for ior-hard to improve scaling, or use wide striping
  lfs setstripe -c ${osts} -S 32m $workdir/ior-easy
  #lfs setstripe -C $osts -S 32m $workdir/ior-hard
  lfs setstripe -C $((osts * 5)) -S 64k $workdir/ior-hard
  if (( $(lfs df $workdir | grep -c MDT) > 1 )); then
    lfs setdirstripe -D -c -1 -i -1 $workdir/mdtest-easy
    lfs setdirstripe -D -c -1 -i -1 $workdir/mdtest-hard
  fi
  # Try to use DoM if available, otherwise use default for small files
  lfs setstripe -E 64k -L mdt $workdir/mdtest-easy
  lfs setstripe -E 64k -L mdt $workdir/mdtest-hard
  #lfs setstripe -E 64k -L mdt $workdir/mdtest-rnd
}

# *****  YOU SHOULD NOT EDIT ANYTHING BELOW THIS LINE  *****
set -eo pipefail  # better error handling

if [[ -z "$io500_ini" ]]; then
  echo "error: ini file must be specified.  usage: $0 <config.ini>"
  exit 1
fi
if [[ ! -s "$io500_ini" ]]; then
  echo "error: ini file '$io500_ini' not found or empty"
  exit 2
fi

function get_ini_section_param() {
  local section="$1"
  local param="$2"
  local inside=false

  while read LINE; do
    LINE=$(sed -e 's/ *#.*//' -e '1s/ *= */=/' <<<$LINE)
    $inside && [[ "$LINE" =~ "[.*]" ]] && inside=false && break
    [[ -n "$section" && "$LINE" =~ "[$section]" ]] && inside=true && continue
    ! $inside && continue
    #echo $LINE | awk -F = "/^$param/ { print \$2 }"
    if [[ $(echo $LINE | grep "^$param *=" ) != "" ]] ; then
      # echo "$section : $param : $inside : $LINE" >> parsed.txt # debugging
      echo $LINE | sed -e "s/[^=]*=[ \t]*\(.*\)/\1/"
      return
    fi
  done < $io500_ini
  echo ""
}

function get_ini_global_param() {
  local param="$1"
  local default="$2"
  local val

  val=$(get_ini_section_param global $param |
  	sed -e 's/[Ff][Aa][Ll][Ss][Ee]/False/' -e 's/[Tt][Rr][Uu][Ee]/True/')

  echo "${val:-$default}"
}

function run_benchmarks {
  $io500_mpirun $io500_mpiargs $np $PWD/io500 $io500_ini --timestamp $timestamp
}

create_tarball() {
  local sourcedir=$(dirname $io500_resultdir)
  local fname=$(basename ${io500_resultdir})
  local tarball=$sourcedir/io500-$HOSTNAME-$fname.tgz

  cp -v $0 $io500_ini $io500_resultdir
  tar czf $tarball -C $sourcedir $fname
  echo "Created result tarball $tarball"
}

function main {
  # These commands extract the 'datadir' and 'resultdir' from .ini file
  timestamp=$(date +%Y.%m.%d-%H.%M.%S)           # create a uniquifier
  [ $(get_ini_global_param timestamp-datadir True) != "False" ] &&
    ts="$timestamp" || ts="io500"
  # working directory where the test files will be created
  export io500_workdir=$(get_ini_global_param datadir $PWD/datafiles)/$ts
  [ $(get_ini_global_param timestamp-resultdir True) != "False" ] &&
    ts="$timestamp" || ts="io500"
  # the directory where the output results will be kept
  export io500_resultdir=$(get_ini_global_param resultdir $PWD/results)/$ts

  setup $io500_workdir $io500_resultdir
  run_benchmarks

  if [[ ! -s "system-information.txt" ]]; then
    echo "Warning: please create a 'system-information.txt' description by"
    echo "copying the information from https://vi4io.org/io500-info-creator/"
  else
    cp "system-information.txt" $io500_resultdir
  fi

  create_tarball
}

main
```

